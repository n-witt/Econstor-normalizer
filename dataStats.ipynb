{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Stats\n",
    "This notebook is supposed to give some insight into corpus and tries to answer some questions like:\n",
    "- How documents are there?\n",
    "- In what language are they written\n",
    "- What is the avarage length of the writings\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = 'data/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of files\n",
    "import os, os.path\n",
    "import json\n",
    "\n",
    "stats = {\n",
    "    'numDocs': 0,\n",
    "    'lang': {},\n",
    "    'hasPlaintext': 0,\n",
    "    'docLen': [],\n",
    "    'citationCounts': {\n",
    "        'cites': [],\n",
    "        'citedBy': []\n",
    "    },\n",
    "    'hasRepecHdl': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [name for name in os.listdir(dataDir) \\\n",
    "         if os.path.isfile(os.path.join(dataDir, name))]\n",
    "\n",
    "stats['numDocs'] = len(files)\n",
    "test = 0\n",
    "isEnglish = set()\n",
    "hasCitation = set()\n",
    "hasPlaintext = set()\n",
    "\n",
    "for doc in files:\n",
    "    with open(os.path.join(dataDir, doc)) as fh:\n",
    "        try:\n",
    "            jsonDoc = json.load(fh)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    # lang\n",
    "    if 'lang' in jsonDoc:\n",
    "        if jsonDoc['lang'] in stats['lang']:\n",
    "            stats['lang'][jsonDoc['lang']] += 1\n",
    "            if jsonDoc['lang'] == 'en':\n",
    "                isEnglish.add(doc)\n",
    "        else:\n",
    "            stats['lang'][jsonDoc['lang']] = 1\n",
    "    \n",
    "    # has plaintext\n",
    "    if 'plaintext' in jsonDoc and len(jsonDoc['plaintext']) > 0:\n",
    "        stats['hasPlaintext'] += 1\n",
    "        # average # of words\n",
    "        stats['docLen'].append(len(jsonDoc['plaintext'].split()))\n",
    "        hasPlaintext.add(doc)\n",
    "        \n",
    "    # citation count\n",
    "    if 'citedBy' in jsonDoc and 'cites' in jsonDoc:\n",
    "        if jsonDoc['citedBy'] is not None or jsonDoc['cites'] is not None:\n",
    "            if isinstance(jsonDoc['cites'], str):\n",
    "                stats['citationCounts']['cites'].append(int(jsonDoc['cites']))\n",
    "                hasCitation.add(doc)\n",
    "            else:\n",
    "                stats['citationCounts']['cites'].append(0)\n",
    "            \n",
    "            if isinstance(jsonDoc['citedBy'], str):\n",
    "                stats['citationCounts']['citedBy'].append(int(jsonDoc['citedBy']))\n",
    "                hasCitation.add(doc)\n",
    "            else:\n",
    "                stats['citationCounts']['citedBy'].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation and visualization\n",
    "### Document lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "docLen = np.array(stats['docLen'])\n",
    "docLenMean = docLen.mean()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "numBins = 1000\n",
    "ax.hist(docLen, numBins ,color='green' ,alpha=0.8)\n",
    "plt.axvline(docLenMean, color='r')\n",
    "plt.xlim(1, 20000)\n",
    "plt.xlabel('Document Length')\n",
    "plt.ylabel('# of Documents')\n",
    "plt.title('Distribution of text length (in words per Document)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cites = np.array(stats['citationCounts']['cites'])\n",
    "citesMean = cites.mean()\n",
    "citedBy = np.array(stats['citationCounts']['citedBy'])\n",
    "citedByMean = citedBy.mean()\n",
    "\n",
    "plt.style.use('bmh')\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, figsize=(10,8))\n",
    "\n",
    "numBins = 100\n",
    "ax0.hist(cites, numBins, color='green', alpha=0.8, histtype=\"stepfilled\")\n",
    "ax0.set_xlabel('cites')\n",
    "ax0.set_ylabel('# of Documents')\n",
    "ax0.set_xlim(0, 120)\n",
    "ax0.set_ylim(0, 8000)\n",
    "ax0.axvline(citesMean, color='r')\n",
    "\n",
    "numBins = 700\n",
    "ax1.hist(citedBy, numBins, color='blue', alpha=0.8, histtype=\"stepfilled\")\n",
    "ax1.set_xlabel('citedBy')\n",
    "ax1.set_ylabel('# of Documents')\n",
    "ax1.set_xlim(0, 35)\n",
    "ax1.set_ylim(0, 6000)\n",
    "ax1.axvline(citedByMean, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### language distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sumResiduals(data, threshold=200):\n",
    "    sortedData = sorted(stats['lang'].items(), key=lambda x: -x[1])\n",
    "    residualsSum = 0\n",
    "    shortendList = {}\n",
    "    for l, count in sortedData:\n",
    "        if count > threshold:\n",
    "            shortendList[l] = count\n",
    "        else:\n",
    "            residualsSum += count\n",
    "    \n",
    "    shortendList['others'] = residualsSum\n",
    "    return shortendList\n",
    "    \n",
    "\n",
    "data = sumResiduals(stats['lang'], 1000)\n",
    "labels = list(data.keys())\n",
    "sizes = [data[l] for l in labels]\n",
    "colors = ['lightskyblue', 'lightcoral', 'gold']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', startangle=-90)\n",
    "plt.title('Languages')\n",
    "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### useful documents\n",
    "##### criteria\n",
    "- english\n",
    "- has citation information\n",
    "- has plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "\n",
    "print(\"isEnglish ∩ hasCitation ∩ hasPlaintext: \" + \\\n",
    "      str(len(isEnglish.intersection(hasCitation).intersection(hasPlaintext))))\n",
    "      \n",
    "venn3([isEnglish, hasCitation, hasPlaintext],\n",
    "      set_labels=('is English','has Citation','has Plaintext'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
