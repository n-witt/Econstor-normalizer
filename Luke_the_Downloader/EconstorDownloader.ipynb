{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luke the Downloader\n",
    "\n",
    "This script downloads files that are occur in XML files generated by the [Econbiz API](https://api.econbiz.de/doc) ([Example](https://api.econbiz.de/v1/search?q=serendipity)).\n",
    "\n",
    "## Workflow\n",
    "1. Generate a XML file using the Econbiz API\n",
    "2. Rename the file to 'econbiz.xml' or change the `metadataFile` variable according to the file name and copy the file into the working directory of this notebook\n",
    "3. Run the notebook\n",
    "\n",
    "## Output\n",
    "A directory called `data` including the subdirectories `pdf`, `json`, `failed` will be created in the working directory.\n",
    "1. `pdf` stores the PDF files\n",
    "2. `json` includes the corresponding meta data.\n",
    "3. `failed` keeps track of files that couldn't be downloaded\n",
    "\n",
    "The meta data of a file with name `pdf/foobar.pdf` can be found in `json/foobar.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the RePec handle\n",
    "In order to receive citation count data from RePec for a given Econbiz document the corresponding RePec handle (a unique identifier) is required.\n",
    "Unfortunately, there is no straight-forward way to do so. This notebook implements several ways to obtain the RePec handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wolfgang's method\n",
    "This method obtains the RePec handle through two stages of indirection from a given Econbiz ID (e.g. 10011374989).\n",
    "1. Receive more data for the Econbiz item at hand through the `/record` method of the [Econbiz API](https://api.econbiz.de/doc)\n",
    "2. Find the [Handle.net](http://handle.net)-handler in the `identifier_number` field\n",
    "3. Use Wolfgang's handle.net-handler to repec-handler (a lot of handles here, i know ;)) [service](http://www.econstor.eu/repec/handleToRepec/<Handle.net-handle>) to obtain the RePec handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "\n",
    "maxNumDocs = 200000\n",
    "\n",
    "def readData(path='repec.json'):\n",
    "    # helper function that reads the data and \n",
    "    # converts it to python objects\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def apiToJson(url, toFile=True, cacheFile='repec.json'):\n",
    "    eBData = urllib2.urlopen(url)\n",
    "    eBData = json.loads(eBData.read())\n",
    "    if toFile and (type(cacheFile) == str or type(cacheFile) == unicode) and len(cacheFile) > 0:\n",
    "        with open(cacheFile, 'w+') as f:\n",
    "            json.dump(eBData, f)\n",
    "    elif toFile == False:\n",
    "        return json.dumps(eBData)\n",
    "    else:\n",
    "        raise ArgumentValidationError('If `toFile` is set to True you need to pass a valid path in the `cacheFile` parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib2\n",
    "import re\n",
    "from urllib2 import URLError\n",
    "import xmltodict\n",
    "import os\n",
    "\n",
    "def determineRepecHandle_WolfgangsMethod(id):\n",
    "    def fetchRepecHandler(id):\n",
    "        # Pass the Econbiz ID an receive the RePec handler (if exists) \n",
    "        try:\n",
    "            econbizRecordURL = 'http://api.econbiz.de/v1/record/' + id\n",
    "        except TypeError:\n",
    "            raise TypeError('You need to pass the id as a str or unicode.')\n",
    "        try:\n",
    "            # fetch more details corresponding to current item\n",
    "            # looking for a handle.net handle\n",
    "            itemMetadata = urllib2.urlopen(econbizRecordURL).read().decode('utf8')\n",
    "            itemMetadata = json.loads(itemMetadata)\n",
    "        except Exception:\n",
    "            raise IOError(\"Couldn't read ressource. Not a JSON file?\")\n",
    "        else:\n",
    "            for identifier_url in itemMetadata['record']['identifier_number']:\n",
    "                # is it a handle.net handle?\n",
    "                if re.match(r'(hdl:)?[0-9]{4,6}/[0-9]{3,6} \\[[H|h]andle\\]', identifier_url) != None:\n",
    "                    match = re.search(r'[0-9]{4,6}/[0-9]{3,6}', identifier_url)\n",
    "                    if match != None:\n",
    "                        hdlStrings = match.group().split('/')            \n",
    "\n",
    "            # do we have a valid handle.net-handle?\n",
    "            if type(hdlStrings) == list:\n",
    "                handleToRepecUrl = 'http://www.econstor.eu/repec/handleToRepec/' + hdlStrings[0] + '/' + hdlStrings[1] + '.txt'\n",
    "                try:\n",
    "                    return urllib2.urlopen(handleToRepecUrl).read()\n",
    "                except URLError:\n",
    "                    return None\n",
    "    \n",
    "        \n",
    "    cacheFile = 'wolfgangsCache.json'\n",
    "    # LookUpTable\n",
    "    lut = {}\n",
    "    \n",
    "    # read cache file an return repec handler if existing\n",
    "    if os.path.exists(cacheFile):\n",
    "        with open(cacheFile) as f:\n",
    "            lut = json.load(f)\n",
    "        if lut.has_key(id):\n",
    "            return lut[id]\n",
    "    \n",
    "    # handler not in local cache. fetch and persist it\n",
    "    repecHandler = fetchRepecHandler(id)\n",
    "    lut.update({id: repecHandler})\n",
    "    with open(cacheFile, 'w+') as f:\n",
    "        json.dump(lut, f)\n",
    "            \n",
    "    return repecHandler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many RePec handles are uncovered by Wolfgang's method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apiToJson(url='http://api.econbiz.de/v1/search?q=source:econstor+identifier_url:pdf&secret=Z-8_uu&size=' + str(maxNumDocs) + '&fields=title,identifier_url,person,date,id', cacheFile='wolfgangsMetadata.json')\n",
    "data = readData('wolfgangsMetadata.json')\n",
    "\n",
    "hasRepec = 0\n",
    "numDocs = len(data['hits']['hits'])\n",
    "for i, item in enumerate(data['hits']['hits']):\n",
    "    try:\n",
    "        repecHdl = determineRepecHandle_WolfgangsMethod(item['id'])\n",
    "    except:\n",
    "        # we don't care about any errors ;)\n",
    "        continue\n",
    "    if repecHdl != None:\n",
    "        hasRepec += 1\n",
    "    if i % 1000 == 0:\n",
    "        print \"{:.1f}% finished\".format((i/float(numDocs))*100)\n",
    "print \"\\nRESULT:\\n{:.1f}% item have a repec handle\".format((hasRepec/float(numDocs))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Henning's method\n",
    "In contrast to Wolfgang's method, Henning's method is more direct and concise as it receives RePec handles from the Econbiz API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "import os\n",
    "\n",
    "def determineRepecHandle_HenningsMethod():\n",
    "    '''\n",
    "    For efficiency reasons (using closures), this methods returns \n",
    "    a methods that allows querying the dataset using an Econbiz ID,\n",
    "    instead of doing the job itself.\n",
    "    '''\n",
    "    cacheFile = 'hanningsCache.json'\n",
    "    if os.path.exists(cacheFile):\n",
    "        with open(cacheFile) as f:\n",
    "            eBData = json.load(f)\n",
    "    else:\n",
    "        eBData = urllib2.urlopen('http://api.econbiz.de/v1/search?q=source:econstor+identifier_url:pdf&secret=Z-8_uu&size=' + str(maxNumDocs) + '&fields=title,identifier_url,person,date,id,identifier_repec')\n",
    "        eBData = json.loads(eBData.read())\n",
    "        with open(cacheFile, 'w+') as f:\n",
    "            json.dump(eBData, f)\n",
    "\n",
    "    lookupTable = {i['id']: i['identifier_repec'] for i in eBData['hits']['hits'] if i.has_key('identifier_repec')}\n",
    "    \n",
    "    def lookup(id):\n",
    "        if type(id) != str and type(id) != unicode:\n",
    "            raise TypeError('You need to pass the id as a str or unicode.')    \n",
    "        try:\n",
    "            return lookupTable[id]\n",
    "        except KeyError:\n",
    "            return None\n",
    "    \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many RePec handles are uncovered by Henning's method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apiToJson(url='http://api.econbiz.de/v1/search?q=source:econstor+identifier_url:pdf&secret=Z-8_uu&size=' + str(maxNumDocs) + '&fields=title,identifier_url,person,date,id,identifier_repec', cacheFile='henningsMetadata.json')\n",
    "data = readData('henningsMetadata.json')\n",
    "\n",
    "hasRepec = 0\n",
    "numDocs = len(data['hits']['hits'])\n",
    "lookup = determineRepecHandle_HenningsMethod()\n",
    "for i, item in enumerate(data['hits']['hits']):\n",
    "    try:\n",
    "        id = lookup(item['id'])\n",
    "    except:\n",
    "        # we don't care about any errors ;)\n",
    "        continue\n",
    "    if id != None:\n",
    "        hasRepec += 1\n",
    "    if i % 1000 == 0:\n",
    "        print \"{:.1f}% finished\".format((i/float(numDocs))*100)\n",
    "print \"\\nRESULT:\\n{:.1f}% item have a repec handle\".format((hasRepec/float(numDocs))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what is the intersection between both results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = readData('henningsMetadata.json')\n",
    "henningsMethod = determineRepecHandle_HenningsMethod()\n",
    "\n",
    "henningsSet = set()\n",
    "wolfgangsSet = set()\n",
    "numDocs = len(data['hits']['hits'])\n",
    "\n",
    "for i, item in enumerate(data['hits']['hits']):\n",
    "    try:\n",
    "        eBId = item['id']\n",
    "    except TypeError:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            henningsId = henningsMethod(eBId)\n",
    "            wolfgangsId = determineRepecHandle_WolfgangsMethod(eBId)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            if henningsId != None:\n",
    "                henningsSet.add(henningsId)\n",
    "            if wolfgangsId != None:\n",
    "                wolfgangsSet.add(wolfgangsId)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print \"{:.1f}% finished\".format((i/float(numDocs))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def citationCount(repecHdl):            \n",
    "    # do we have a valid repec-handle?\n",
    "    if type(repecHdl) == str or type(repecHdl) == unicode:\n",
    "        citecUrl = 'http://citec.repec.org/api/plain/' + repecHdl\n",
    "        try:\n",
    "            citationData = xmltodict.parse(urllib2.urlopen(citecUrl).read())\n",
    "        except URLError:\n",
    "            raise URLError('Couldn\\'t fetch data. Check you Configuration and' + \\\n",
    "                          'the availability of http://citec.repec.org')\n",
    "        else:\n",
    "            citedBy = int(citationData['citationData']['citedBy'])\n",
    "            cites = int(citationData['citationData']['cites'])\n",
    "            return {'citedBy': citedBy, 'cites': cites}\n",
    "    else:\n",
    "        raise TypeError('You need to pass a string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib2\n",
    "import logging\n",
    "import re\n",
    "import xmltodict\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "wd = os.getcwd() + os.sep + '..' + os.sep + 'data'\n",
    "metadataFile = 'econstor.json'\n",
    "failedPath = 'failedToDownload.json'\n",
    "\n",
    "\n",
    "def mkDir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "with open(metadataFile, \"r\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "    if data.has_key(\"hits\") and data[\"hits\"].has_key(\"hits\"):\n",
    "        data = data[\"hits\"][\"hits\"]\n",
    "    else:\n",
    "        raise Exception(\"unknown Datastructure\")\n",
    "# create directories if not existing\n",
    "pdfDir = wd + os.sep +  u'pdf'\n",
    "jsonDir = wd  + os.sep + u'json'\n",
    "failDir = wd + os.sep + os.sep + u'failed'\n",
    "for f in (pdfDir, jsonDir, failDir):\n",
    "    mkDir(f)\n",
    "    \n",
    "u = \"\"\n",
    "failedDownloads = []\n",
    "for item in data:\n",
    "    url = item[\"identifier_url\"][0]\n",
    "    filename = url.split(\"/\")[-1]        \n",
    "    try:\n",
    "        # download the pdf file\n",
    "        if not os.path.exists(pdfDir + os.sep + filename):\n",
    "            u = urllib2.urlopen(url)\n",
    "            with open(pdfDir + os.sep + filename, 'w') as f:\n",
    "                f.write(u.read())\n",
    "            logging.log(logging.INFO, filename + \" successfully downloaded.\")\n",
    "        else:\n",
    "            logging.log(logging.INFO, filename + \" skipped. already downloaded.\")        \n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.log(logging.INFO, url + \" couldn't be opened.\") \n",
    "        failedDownloads.append(item)\n",
    "        logging.error(logging.ERROR, e)\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        # write meta data to json file\n",
    "        metadata = json.dumps(item)\n",
    "        if os.path.exists(filename):\n",
    "            logging.log(logging.INFO, filename + u'.json' + \"exists already. skipping file.\")\n",
    "        else:\n",
    "            localFile = open(jsonDir + os.sep + filename + u'.json', 'w')\n",
    "            localFile.write(metadata)\n",
    "            localFile.close() \n",
    "            logging.log(logging.INFO, filename + u'.json' + \" meta data file written\")\n",
    "\n",
    "\n",
    "if len(failedDownloads) > 0:\n",
    "    handler = open(failDir + os.sep + failedPath, \"w\")\n",
    "    handler.write(json.dumps(failedDownloads))\n",
    "logging.log(logging.INFO, \"Downloads complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
